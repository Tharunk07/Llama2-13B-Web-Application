<h1>Llama-2-13B Model</h1>

The Llama-2-13B model is a machine learning model deployed on the Google Cloud Platform (GCP) cloud platform. It is accessed locally through a user-friendly interface created with Streamlit, allowing users to send requests and receive responses from the model.

<h2>Technologies Used</h2>
**Python**: The primary programming language used for developing the model and the interface.
**google-auth**: This library is utilized for authenticating with Google Cloud services.
**Google Cloud Service**: The Google Cloud Platform is used for hosting and deploying the model.
**Streamlit**: Streamlit is employed for creating the interactive web interface for accessing the model.

<h2>Getting Started</h2>
To get started with using the Llama-2-13B model, follow these steps:

**Installation**: Ensure you have Python installed on your local system. Use pip to install the necessary dependencies:
'''
echo "pip install -r requirements.txt"

'''
